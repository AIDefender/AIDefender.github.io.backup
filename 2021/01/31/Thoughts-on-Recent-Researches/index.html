<!DOCTYPE html>



  


<html class="theme-next mist use-motion" lang="en">
<head>
  <!-- hexo-inject:begin --><!-- hexo-inject:end --><meta charset="UTF-8"/>
<meta http-equiv="X-UA-Compatible" content="IE=edge" />
<meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"/>
<meta name="theme-color" content="#222">









<meta http-equiv="Cache-Control" content="no-transform" />
<meta http-equiv="Cache-Control" content="no-siteapp" />
















  
  
  <link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css" />







<link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css" />

<link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css" />


  <link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4">


  <link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4">


  <link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222">





  <meta name="keywords" content="RL Research," />










<meta name="description" content="A high-level summary of recent experiements and thoughts on papers I read. Covered topics are:&amp;ensp;1. preferred policy distributions in common RL algorithms; 2. issues with policy distribution:&amp;ensp;">
<meta property="og:type" content="article">
<meta property="og:title" content="Thoughts on Recent Researches">
<meta property="og:url" content="http://aidefender.github.io/2021/01/31/Thoughts-on-Recent-Researches/index.html">
<meta property="og:site_name" content="Zhenghai Xue&#39;s HomePage">
<meta property="og:description" content="A high-level summary of recent experiements and thoughts on papers I read. Covered topics are:&amp;ensp;1. preferred policy distributions in common RL algorithms; 2. issues with policy distribution:&amp;ensp;">
<meta property="og:locale" content="en_US">
<meta property="article:published_time" content="2021-01-31T02:42:29.000Z">
<meta property="article:modified_time" content="2021-02-24T03:32:21.385Z">
<meta property="article:author" content="Zhenghai Xue">
<meta property="article:tag" content="RL Research">
<meta name="twitter:card" content="summary">



<script type="text/javascript" id="hexo.configurations">
  var NexT = window.NexT || {};
  var CONFIG = {
    root: '/',
    scheme: 'Mist',
    version: '5.1.4',
    sidebar: {"position":"left","display":"always","offset":12,"b2t":false,"scrollpercent":false,"onmobile":false},
    fancybox: true,
    tabs: true,
    motion: {"enable":true,"async":false,"transition":{"post_block":"fadeIn","post_header":"slideDownIn","post_body":"slideDownIn","coll_header":"slideLeftIn","sidebar":"slideUpIn"}},
    duoshuo: {
      userId: '0',
      author: 'Author'
    },
    algolia: {
      applicationID: '',
      apiKey: '',
      indexName: '',
      hits: {"per_page":10},
      labels: {"input_placeholder":"Search for Posts","hits_empty":"We didn't find any results for the search: ${query}","hits_stats":"${hits} results found in ${time} ms"}
    }
  };
</script>



  <link rel="canonical" href="http://aidefender.github.io/2021/01/31/Thoughts-on-Recent-Researches/"/>





  <title>Thoughts on Recent Researches | Zhenghai Xue's HomePage</title>
  








<meta name="generator" content="Hexo 4.2.0"><!-- hexo-inject:begin --><!-- hexo-inject:end --></head>

<body itemscope itemtype="http://schema.org/WebPage" lang="en">

  
  
    
  

  <!-- hexo-inject:begin --><!-- hexo-inject:end --><div class="container sidebar-position-left page-post-detail">
    <div class="headband"></div>

    <header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader">
      <div class="header-inner"><div class="site-brand-wrapper">
  <div class="site-meta ">
    

    <div class="custom-logo-site-title">
      <a href="/"  class="brand" rel="start">
        <span class="logo-line-before"><i></i></span>
        <span class="site-title">Zhenghai Xue's HomePage</span>
        <span class="logo-line-after"><i></i></span>
      </a>
    </div>
      
        <p class="site-subtitle"></p>
      
  </div>

  <div class="site-nav-toggle">
    <button>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
      <span class="btn-bar"></span>
    </button>
  </div>
</div>

<nav class="site-nav">
  

  
    <ul id="menu" class="menu">
      
        
        <li class="menu-item menu-item-home">
          <a href="/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-home"></i> <br />
            
            Home
          </a>
        </li>
      
        
        <li class="menu-item menu-item-tags">
          <a href="/tags/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-tags"></i> <br />
            
            Tags
          </a>
        </li>
      
        
        <li class="menu-item menu-item-archives">
          <a href="/archives/" rel="section">
            
              <i class="menu-item-icon fa fa-fw fa-archive"></i> <br />
            
            Archives
          </a>
        </li>
      

      
    </ul>
  

  
</nav>



 </div>
    </header>

    <main id="main" class="main">
      <div class="main-inner">
        <div class="content-wrap">
          <div id="content" class="content">
            

  <div id="posts" class="posts-expand">
    

  

  
  
  

  <article class="post post-type-normal" itemscope itemtype="http://schema.org/Article">
  
  
  
  <div class="post-block">
    <link itemprop="mainEntityOfPage" href="http://aidefender.github.io/2021/01/31/Thoughts-on-Recent-Researches/">

    <span hidden itemprop="author" itemscope itemtype="http://schema.org/Person">
      <meta itemprop="name" content="Zhenghai Xue">
      <meta itemprop="description" content="">
      <meta itemprop="image" content="/images/avatar.gif">
    </span>

    <span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization">
      <meta itemprop="name" content="Zhenghai Xue's HomePage">
    </span>

    
      <header class="post-header">

        
        
          <h1 class="post-title" itemprop="name headline">Thoughts on Recent Researches</h1>
        

        <div class="post-meta">
          <span class="post-time">
            
              <span class="post-meta-item-icon">
                <i class="fa fa-calendar-o"></i>
              </span>
              
                <span class="post-meta-item-text">Posted on</span>
              
              <time title="Post created" itemprop="dateCreated datePublished" datetime="2021-01-31T10:42:29+08:00">
                2021-01-31
              </time>
            

            

            
          </span>

          

          
            
          

          
          

          

          

          
              <div class="post-description">
                  A high-level summary of recent experiements and thoughts on papers I read. Covered topics are:&ensp;1. preferred policy distributions in common RL algorithms; 2. issues with policy distribution:&ensp;distribution mismatch, lack of corrective feedback and pessimism in face of uncertainty. 3. (TODO) Update-to-Data(UTD) Ratio in RL Algorithms; 4. (TODO) Dyna-style model-based learning, that is, use dynamic model to generate fake transitions, augmenting the model-free replay buffer.
              </div>
          

        </div>
      </header>
    

    
    
    
    <div class="post-body" itemprop="articleBody">

      
      

      
        <h1 id="Policy-Distribution"><a href="#Policy-Distribution" class="headerlink" title="Policy Distribution"></a>Policy Distribution</h1><h2 id="Basics"><a href="#Basics" class="headerlink" title="Basics"></a>Basics</h2><p>Standardized Reinforcement Learning(RL) algorithms can be categorized into two classes: on-policy learning and off-policy learning. Their difference lies in the relationship between behavior policy $\mu$, with which the agent interacts with the environment, and the target policy $\pi$, which the RL algorithm aims to evaluate or improve.  In the on-policy setting,  the behavior policy and target policy are exactly the same, while in the off-policy setting the behavior policy can be any possible policy distribution.</p>
<h2 id="Preferred-policy-distribution-of-common-algorithms"><a href="#Preferred-policy-distribution-of-common-algorithms" class="headerlink" title="Preferred policy distribution of common algorithms"></a>Preferred policy distribution of common algorithms</h2><p>It is well known that the Q-learning update </p>
<script type="math/tex; mode=display">
\label{eq1}
Q_{t+1}(s,a) = Q_t(s,a) + \alpha \left(r(s,a) + \gamma \max\limits_{a'}\mathbb{E}_{s'\sim p(s'|s,a)}[Q_t(s',a')]-Q_t(s,a)\right)</script><p>is off-policy because the max operator is irrelevant to the policy distribution. In contrast, the Q-value evaluation task is on-policy since the evaluation is with regard to the performance of a certain policy.  Its update rule is similar to the on-policy counterpart of Q-learning, SARSA:</p>
<script type="math/tex; mode=display">
Q_{t+1}(s,a) = Q_t(s,a) + \alpha \left(r(s,a) + \gamma ~\mathbb{E}_{a'\sim\pi(s')}\mathbb{E}_{s'\sim p(s'|s,a)}[Q_t(s',a')]-Q_t(s,a)\right)</script><p>Another frequently used technique in RL is  Policy Gradient(PG), where the max-return objective is achieved by directly taking the derivative w.r.t. the policy parameters.  PG methods are naturally on-policy, and even though some of its variants, like PPO and TRPO, utilize important sampling which is commonly used in off-policy evaluation, these algorithms can not work well in a complete off-policy setting.</p>
<h2 id="Issues-with-policy-distribution-of-common-algorithms"><a href="#Issues-with-policy-distribution-of-common-algorithms" class="headerlink" title="Issues with policy distribution of common algorithms"></a>Issues with policy distribution of common algorithms</h2><h3 id="Distribution-mismatch"><a href="#Distribution-mismatch" class="headerlink" title="Distribution mismatch"></a>Distribution mismatch</h3><p>The critic learning of Soft Actor Critic(SAC) is basically Q-value evaluation: the action of the next step in Bellman equation is chosen according to the <strong>current</strong> policy. In the implementation of SAC, the actions used in the Bellman equation in Q evaluation is indeed sampled from the current policy distribution, while the states are simply sampled from the replay buffer, which contains trajectories of <strong>mixed</strong> policies. This gives rise to a mismatch in state distribution. <a href="#1">[1]</a> corrects this by computing important ratio based on the replay buffer. The ratio emphasizes samples which are more likely to appear under the stationary state distribution of the current policy. The ratio is attained by solving an optimization problem, and the overall algorithm is basically a min-max optimization.</p>
<h3 id="Lack-of-corrective-feedback"><a href="#Lack-of-corrective-feedback" class="headerlink" title="Lack of corrective feedback"></a>Lack of corrective feedback</h3><p>Equation $(\ref{eq1})$ is about the <strong>exact</strong> computation of Q function. In modern deep Q-learning, where the Q function is approximated by a neural network, we must take the estimation error into consideration.</p>
<h3 id="Pessimism-in-face-of-uncertainty"><a href="#Pessimism-in-face-of-uncertainty" class="headerlink" title="Pessimism in face of uncertainty"></a>Pessimism in face of uncertainty</h3><h1 id="Update-to-Data-UTD-Ratio-in-RL-Algorithms"><a href="#Update-to-Data-UTD-Ratio-in-RL-Algorithms" class="headerlink" title="Update-to-Data(UTD) Ratio in RL Algorithms"></a>Update-to-Data(UTD) Ratio in RL Algorithms</h1><h1 id="Dyna-style-Model-based-Learning"><a href="#Dyna-style-Model-based-Learning" class="headerlink" title="Dyna-style Model-based Learning"></a>Dyna-style Model-based Learning</h1><p>This blog is based on results from my experiments and following research papers:</p>
<p><span id="1">[1]</span> Sinha, Samarth, et al. “Experience Replay with Likelihood-free Importance Weights.” <em>arXiv preprint arXiv:2006.13169</em> (2020).</p>

      
    </div>
    
    
    

    

    

    

    <footer class="post-footer">
      
        <div class="post-tags">
          
            <a href="/tags/RL-Research/" rel="tag"># RL Research</a>
          
        </div>
      

      
      
      

      
        <div class="post-nav">
          <div class="post-nav-next post-nav-item">
            
              <a href="/2020/05/19/Advances-in-2020-5/" rel="next" title="Advances in 2020-5">
                <i class="fa fa-chevron-left"></i> Advances in 2020-5
              </a>
            
          </div>

          <span class="post-nav-divider"></span>

          <div class="post-nav-prev post-nav-item">
            
              <a href="/2021/03/20/Thoughts-on-Model-based-Transfer-Learning/" rel="prev" title="Thoughts on Model-Based Transfer Learning">
                Thoughts on Model-Based Transfer Learning <i class="fa fa-chevron-right"></i>
              </a>
            
          </div>
        </div>
      

      
      
    </footer>
  </div>
  
  
  
  </article>



    <div class="post-spread">
      
    </div>
  </div>


          </div>
          


          

  



        </div>
        
          
  
  <div class="sidebar-toggle">
    <div class="sidebar-toggle-line-wrap">
      <span class="sidebar-toggle-line sidebar-toggle-line-first"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span>
      <span class="sidebar-toggle-line sidebar-toggle-line-last"></span>
    </div>
  </div>

  <aside id="sidebar" class="sidebar">
    
    <div class="sidebar-inner">

      

      
        <ul class="sidebar-nav motion-element">
          <li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">
            Table of Contents
          </li>
          <li class="sidebar-nav-overview" data-target="site-overview-wrap">
            Overview
          </li>
        </ul>
      

      <section class="site-overview-wrap sidebar-panel">
        <div class="site-overview">
          <div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person">
            
              <p class="site-author-name" itemprop="name">Zhenghai Xue</p>
              <p class="site-description motion-element" itemprop="description">3rd Year Undergraduate at AI, NJU</p>
          </div>

          <nav class="site-state motion-element">

            
              <div class="site-state-item site-state-posts">
              
                <a href="/archives/%7C%7C%20archive">
              
                  <span class="site-state-item-count">9</span>
                  <span class="site-state-item-name">posts</span>
                </a>
              </div>
            

            

            
              
              
              <div class="site-state-item site-state-tags">
                <a href="/tags/index.html">
                  <span class="site-state-item-count">3</span>
                  <span class="site-state-item-name">tags</span>
                </a>
              </div>
            

          </nav>

          

          
            <div class="links-of-author motion-element">
                
                  <span class="links-of-author-item">
                    <a href="https://github.com/AIDefender" target="_blank" title="GitHub">
                      
                        <i class="fa fa-fw fa-github"></i>GitHub</a>
                  </span>
                
                  <span class="links-of-author-item">
                    <a href="mailto:xuezh@smail.nju.edu.cn" target="_blank" title="E-Mail">
                      
                        <i class="fa fa-fw fa-envelope"></i>E-Mail</a>
                  </span>
                
            </div>
          

          
          

          
          

          <script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?d=7uuY0rYLIMA5ATNJKbnm3IjeEdmIYhkVKzX8Xnp6Pf8&cl=ffffff&w=a"></script>
        </div>
      </section>

      
      <!--noindex-->
        <section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active">
          <div class="post-toc">

            
              
            

            
              <div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#Policy-Distribution"><span class="nav-number">1.</span> <span class="nav-text">Policy Distribution</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#Basics"><span class="nav-number">1.1.</span> <span class="nav-text">Basics</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Preferred-policy-distribution-of-common-algorithms"><span class="nav-number">1.2.</span> <span class="nav-text">Preferred policy distribution of common algorithms</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#Issues-with-policy-distribution-of-common-algorithms"><span class="nav-number">1.3.</span> <span class="nav-text">Issues with policy distribution of common algorithms</span></a><ol class="nav-child"><li class="nav-item nav-level-3"><a class="nav-link" href="#Distribution-mismatch"><span class="nav-number">1.3.1.</span> <span class="nav-text">Distribution mismatch</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Lack-of-corrective-feedback"><span class="nav-number">1.3.2.</span> <span class="nav-text">Lack of corrective feedback</span></a></li><li class="nav-item nav-level-3"><a class="nav-link" href="#Pessimism-in-face-of-uncertainty"><span class="nav-number">1.3.3.</span> <span class="nav-text">Pessimism in face of uncertainty</span></a></li></ol></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Update-to-Data-UTD-Ratio-in-RL-Algorithms"><span class="nav-number">2.</span> <span class="nav-text">Update-to-Data(UTD) Ratio in RL Algorithms</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#Dyna-style-Model-based-Learning"><span class="nav-number">3.</span> <span class="nav-text">Dyna-style Model-based Learning</span></a></li></ol></div>
            

          </div>
        </section>
      <!--/noindex-->
      

      

    </div>
  </aside>


        
      </div>
    </main>

    <footer id="footer" class="footer">
      <div class="footer-inner">
        <div class="copyright">&copy; 2020 &mdash; <span itemprop="copyrightYear">2021</span>
  <span class="with-love">
    <i class="fa fa-user"></i>
  </span>
  <span class="author" itemprop="copyrightHolder">Zhenghai Xue</span>

  
</div>


  <div class="powered-by">Powered by <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a></div>



  <span class="post-meta-divider">|</span>



  <div class="theme-info">Theme &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Mist</a> v5.1.4</div>




        







        
      </div>
    </footer>

    
      <div class="back-to-top">
        <i class="fa fa-arrow-up"></i>
        
      </div>
    

    

  </div>

  

<script type="text/javascript">
  if (Object.prototype.toString.call(window.Promise) !== '[object Function]') {
    window.Promise = null;
  }
</script>









  












  
  
    <script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script>
  

  
  
    <script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script>
  

  
  
    <script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script>
  

  
  
    <script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script>
  


  


  <script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script>

  <script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script>



  
  

  
  <script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script>
<script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script>



  


  <script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script>



  


  




	





  





  












  





  

  

  

  
  

  
  
    <script type="text/x-mathjax-config">
      MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });
    </script>

    <script type="text/x-mathjax-config">
      MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });
    </script>
    <script type="text/javascript" src="//cdn.jsdelivr.net/npm/mathjax@2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML"></script><!-- hexo-inject:begin --><!-- Begin: Injected MathJax -->
<script type="text/x-mathjax-config">
  MathJax.Hub.Config("");
</script>

<script type="text/x-mathjax-config">
  MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
      all[i].SourceElement().parentNode.className += ' has-jax';
    }
  });
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=default">
</script>
<!-- End: Injected MathJax -->
<!-- hexo-inject:end -->
  


  

  

</body>
</html>
